{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.0-1-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in d:\\yahel\\phd\\courses\\ml in biology research\\final_project\\final_project_ml\\lib\\site-packages (from scikit-learn) (1.26.3)\n",
      "Collecting scipy>=1.6.0\n",
      "  Using cached scipy-1.12.0-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: joblib, scipy, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.4.0 scipy-1.12.0 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'd:\\yahel\\phd\\courses\\ML in biology research\\final_project\\final_project_ml\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\yahel\\\\phd\\\\courses\\\\ML in biology research\\\\final_project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('D:\\yahel\\phd\\courses\\ML in biology research\\\\final_project')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yahelc\\AppData\\Local\\Temp\\ipykernel_14516\\4074392612.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import pickle\n",
    "import copy\n",
    "import glob\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold , train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate ratios\n",
    "# object must be pandas series\n",
    "def calculate_ratio(nome: pd.Series, deno: pd.Series = None):\n",
    "    \"\"\"\n",
    "    function to calculate ratios\n",
    "    :param nome:\n",
    "    :param deno:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    if deno is None:\n",
    "        deno = nome\n",
    "        \n",
    "    return(nome.value_counts() / deno.value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1  ...          No      No                   No   \n",
       "1                 3  ...          No      Up                   No   \n",
       "2                 2  ...          No      No                   No   \n",
       "3                 2  ...          No      Up                   No   \n",
       "4                 1  ...          No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read database #\n",
    "path_to_data = os.path.join('data', 'diabetic_data.csv')\n",
    "whole_data_df = pd.read_csv(path_to_data)\n",
    "whole_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Look at the big picture (Quick look at the data structure)\n",
    "possibale_val_list = [whole_data_df[x].unique() for x in whole_data_df]\n",
    "possibale_val_list = pd.DataFrame(zip(list(whole_data_df.columns),possibale_val_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter dataset for diabetic pateints diagnosed at least once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the unknown valuse in the data to np.nan\n",
    "whole_data_df[whole_data_df == \"?\"] = np.nan\n",
    "whole_data_df[whole_data_df == \"None\"] = np.nan\n",
    "whole_data_df[whole_data_df == \"Unknown/Invalid\"] = np.nan\n",
    "\n",
    "# how many var and obs in data, data types and non -missing values\n",
    "mis = whole_data_df.isna().sum()\n",
    "whole_data_df.info()\n",
    "\n",
    "# drop all fitures with only one value from the data set\n",
    "for fiture in whole_data_df[whole_data_df.columns[2:]]:\n",
    "    if len(set(whole_data_df[fiture])) == 1:\n",
    "        whole_data_df.pop(fiture)\n",
    "whole_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all fitures with only one value from the data set\n",
    "for fiture in whole_data_df[whole_data_df.columns[2:]]:\n",
    "    if len(set(whole_data_df[fiture])) == 1:\n",
    "        whole_data_df.pop(fiture)\n",
    "whole_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38024 encounters out of 101766 total encounters are of diabetic pateints \n",
      " i.e. ~ 37.36% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yahelc\\AppData\\Local\\Temp\\ipykernel_14516\\668848931.py:7: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  diag_count = whole_data_df[diagnosis_cols_list].apply(lambda x: x.str.contains(pattern)).sum(axis =1)\n"
     ]
    }
   ],
   "source": [
    "diagnosis_cols_list = ['diag_' + str(num) for num in [1,2,3]]\n",
    "\n",
    "# Regex pattern to locate diabeteic pateints \n",
    "pattern = r'250(\\.\\d{2})?'\n",
    "\n",
    "# count diabetes diagnosis appearance  in all 3 daignosis columns \n",
    "diag_count = whole_data_df[diagnosis_cols_list].apply(lambda x: x.str.contains(pattern)).sum(axis =1)\n",
    "\n",
    "diabetic_only_df = whole_data_df[diag_count > 0]\n",
    "print('%d encounters out of %d total encounters are of diabetic pateints \\n i.e. ~ %.2f%% '\\\n",
    "    %(diabetic_only_df.shape[0],whole_data_df.shape[0],\n",
    "      (diabetic_only_df.shape[0]/whole_data_df.shape[0])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determine repeated encounter by the same patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6836 encounters are patient repeated ones, ~17.98%\n",
      "count\n",
      "1     26849\n",
      "2      3091\n",
      "3       750\n",
      "4       242\n",
      "5       114\n",
      "6        55\n",
      "7        31\n",
      "8        14\n",
      "10       10\n",
      "11        9\n",
      "9         7\n",
      "15        4\n",
      "12        2\n",
      "14        2\n",
      "17        2\n",
      "28        1\n",
      "13        1\n",
      "18        1\n",
      "19        1\n",
      "22        1\n",
      "38        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "duplicated_encounters = sum(diabetic_only_df['patient_nbr'].duplicated())\n",
    "print('%d encounters are patient repeated ones, ~%.2f%%' % \\\n",
    "    (duplicated_encounters,\n",
    "    (duplicated_encounters/diabetic_only_df.shape[0]*100)))\n",
    "\n",
    "\n",
    "print(diabetic_only_df['patient_nbr'].value_counts().value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_ratio(diabetic_only_df['readmitted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precentage of classes of the labels\n",
      " readmitted\n",
      "NO     0.547102\n",
      ">30    0.343362\n",
      "<30    0.109536\n",
      "Name: count, dtype: float64\n",
      "\n",
      "\n",
      "precenatge of label classes beloning to repeated patients \n",
      " readmitted\n",
      "<30    0.163745\n",
      ">30    0.147212\n",
      "NO     0.083401\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# an imbalanced label! \n",
    "\n",
    "# get the repeated patients readmission labels \n",
    "duplicated_df = diabetic_only_df[diabetic_only_df['patient_nbr'].duplicated()]\n",
    "duplicated_df = duplicated_df[~duplicated_df['patient_nbr'].duplicated()]\n",
    "\n",
    "# the precenatge of \n",
    "print('\\n\\nprecenatge of label classes beloning to repeated patients \\n',duplicated_df['readmitted'].value_counts()/diabetic_only_df['readmitted'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since a large portion of the encounters is a duplication of the same patient \n",
    "## We decided to treat each encounter as a different patient\n",
    "## Therefore for test-train split we will follow the group_stratified split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Complete dataset</th>\n",
       "      <th>Train datset (80%)</th>\n",
       "      <th>Test datset (20%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>readmitted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NO</th>\n",
       "      <td>0.547102</td>\n",
       "      <td>0.547107</td>\n",
       "      <td>0.547080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;30</th>\n",
       "      <td>0.343362</td>\n",
       "      <td>0.343360</td>\n",
       "      <td>0.343372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;30</th>\n",
       "      <td>0.109536</td>\n",
       "      <td>0.109533</td>\n",
       "      <td>0.109548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Complete dataset  Train datset (80%)  Test datset (20%)\n",
       "readmitted                                                         \n",
       "NO                  0.547102            0.547107           0.547080\n",
       ">30                 0.343362            0.343360           0.343372\n",
       "<30                 0.109536            0.109533           0.109548"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 pateint with overlap between train-test cohorts\n"
     ]
    }
   ],
   "source": [
    "# stratify by pateints' ID as group \n",
    "groups_for_stratification = diabetic_only_df['patient_nbr']\n",
    "X = diabetic_only_df.drop('readmitted',axis=1)\n",
    "Y = diabetic_only_df['readmitted']\n",
    "\n",
    "# instentiate the StratifiedGroupKFold class\n",
    "sgkf = StratifiedGroupKFold(n_splits=5) \n",
    "\n",
    "# use the CV split to create 5 spilt of a 80-20 ratio\n",
    "cv_division = sgkf.split(X, Y,groups_for_stratification)\n",
    "\n",
    "# unpack the first one - randomly \n",
    "train_test_index_array, *_ = cv_division\n",
    "\n",
    "train = diabetic_only_df.iloc[train_test_index_array[0]]\n",
    "test = diabetic_only_df.iloc[train_test_index_array[1]]\n",
    "\n",
    "display(pd.DataFrame({'Complete dataset' : calculate_ratio(diabetic_only_df['readmitted']),\n",
    "                      'Train datset (80%)' : calculate_ratio(train['readmitted']),\n",
    "                      'Test datset (20%)' : calculate_ratio(test['readmitted'])}))\n",
    "\n",
    "print('There are %d pateint with overlap between train-test cohorts' % sum(np.in1d(train['patient_nbr'].unique(), test['patient_nbr'].unique())))\n",
    "\n",
    "if len(glob.glob('D:/yahel/phd/courses/ML in biology research/final_project/data/data_split*.csv')) == 0:\n",
    "    train.to_csv(os.path.join(os.getcwd(),'data','data_split','train_cohort.csv'))\n",
    "    test.to_csv(os.path.join(os.getcwd(),'data','data_split','test_cohort.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
